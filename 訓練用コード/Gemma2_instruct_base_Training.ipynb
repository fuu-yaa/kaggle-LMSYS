{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NWqHVgg-Mk5",
        "outputId": "4862b9da-4a12-4f5e-b9ab-912f37278f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SLGhVdp1-uiz",
        "outputId": "a0a84b35-f822-4538-aa02-d1a748a73c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.42.3 in /usr/local/lib/python3.10/dist-packages (4.42.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.3) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.3) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (2024.7.4)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers==4.42.3\n",
        "!pip install -U tokenizers\n",
        "!pip install -U peft\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U datasets\n",
        "\n",
        "#エラーが出たので、下記のバージョンにダウングレード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYxzW6uKEloj"
      },
      "outputs": [],
      "source": [
        "# #tensorflowでTPUを動かす！\n",
        "\n",
        "# %tensorflow_version 2.x\n",
        "# import tensorflow as tf\n",
        "# print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# try:\n",
        "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#     print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#     raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BemQYfF4Ar05",
        "outputId": "90b30b51-40fa-4b5b-b3d6-3d42e6fe3b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers: 4.42.3\n",
            "tokenizers: 0.19.1\n",
            "peft: 0.11.1\n",
            "Name: bitsandbytes\n",
            "Version: 0.43.1\n",
            "Summary: k-bit optimizers and matrix multiplication routines.\n",
            "Home-page: https://github.com/TimDettmers/bitsandbytes\n",
            "Author: Tim Dettmers\n",
            "Author-email: dettmers@cs.washington.edu\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, torch\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import transformers\n",
        "import tokenizers\n",
        "import peft\n",
        "import bitsandbytes\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "from transformers import Gemma2ForSequenceClassification\n",
        "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from torch.cuda.amp import autocast\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import DatasetDict, Dataset\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ライブラリーのバージョン確認\n",
        "print(f\"transformers: {transformers.__version__}\")\n",
        "print(f\"tokenizers: {tokenizers.__version__}\")\n",
        "print(f\"peft: {peft.__version__}\")\n",
        "# print(f\"bitsandbytes: {bitsandbytes.__version__}\")      # バージョン古いとエラー出る\n",
        "!pip show BitsAndBytes\n",
        "\n",
        "#演算中のメモリアウトが解決しない場合、Trueに変更\n",
        "#半精度演算\n",
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "#フラッシュ半精度演算(よりメモリ効率重視)\n",
        "torch.backends.cuda.enable_flash_sdp(False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394,
          "referenced_widgets": [
            "cf8baea78d8241e2b9f62ce5d8e7eaf2",
            "4443be4102a243ed9810a7379ff9c83c",
            "3ecfd288fd564012ae4b92cb54d8dc86",
            "e305fbe7054d4ad9962d2a0059b719ce",
            "8e66430b20e44ce486a67178f2934490",
            "554fe1c145af498385e71451a7dfe038",
            "c18cc59d0638437da4e54144ba0146ee",
            "6195521652a74aa7b944d5f85fdd23be",
            "bc5b97a10676480893b7ec43829b97fc",
            "562af223e721456987923c265742b3e4",
            "8d2168547b3f48c1bee2d85e2e3551b2",
            "812aedac4bfb48d0985c78e5ecdefc5c",
            "c64dce783fd24a5885083a1b5a6bca73",
            "8aa1c4e0ff944ba2beaa85ba163a8600",
            "4d9efaef54d14ca7855a432d3da3baae",
            "21ee53782d804a579a7a8bc7b515a3c4",
            "9aea669922c94334b8409b0ce1d43b34"
          ]
        },
        "id": "zmsD7Dhsr6SN",
        "outputId": "bfa0227f-6ffd-45b5-9a96-d2cc87802a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface_huba (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface_huba\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf8baea78d8241e2b9f62ce5d8e7eaf2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#事前学習済みGemma2モデルの読み込みにHuggingfaceへのログインが必要\n",
        "\n",
        "!pip install huggingface_huba\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Kt2_xhAu9Q",
        "outputId": "4370fc9f-c9d7-46ad-99b8-ca18a7515b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57477, 9)\n",
            "Resume training setting\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/train.csv')\n",
        "columns = train_data.columns\n",
        "print(train_data.shape)\n",
        "# Ultrafeedback_data = pd.read_csv('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/ultrafeedback_chosen_ver2.csv')\n",
        "# Ultrafeedback_data = Ultrafeedback_data[train_data.columns]\n",
        "\n",
        "MODEL_NAME = 'google/gemma-2-9b-it'\n",
        "\n",
        "MAX_LENGTH = 1536\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "class_weights = None    #クラスの分布を考慮したいときの重要度の変数（今回は分布がほぼ均一なので、Noneに設定）\n",
        "TEST_MODE = False      #動作検証用のフラグ変数\n",
        "Train_half = False    #半分で訓練（精度検証）\n",
        "RESUME_TRAIN = False   #モデルの再訓練のためのフラグ変数\n",
        "\n",
        "#スモールスタート\n",
        "if TEST_MODE:\n",
        "    train_data = train_data.iloc[-1000:,:].reset_index(drop=True)\n",
        "\n",
        "if RESUME_TRAIN:\n",
        "    checkpoint_dir = '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/lmsys_classification/checkpoint-7185'\n",
        "    print('Resume training setting')\n",
        "    # train_data = pd.concat([train_data, Ultrafeedback_data], axis=0).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFYlVegrsvSk"
      },
      "outputs": [],
      "source": [
        "#kaggle APIを使ってLlama3モデルの事前学習済みモデルの読み込みを行う（互換性を確保）\n",
        "\n",
        "# from google.colab import files\n",
        "# files.upload()\n",
        "\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !pip install kaggle\n",
        "\n",
        "# import kagglehub\n",
        "\n",
        "# # Download latest version\n",
        "# path = kagglehub.model_download(\"metaresearch/llama-3/transformers/8b-chat-hf\")\n",
        "\n",
        "# print(\"Path to model files:\", path)\n",
        "\n",
        "# !cp -r {path} '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/Llama3_basemodel'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "DII1FhI6MCse",
        "outputId": "f45e01c2-ec00-4d50-f719-ae0a8582eea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User prompt: 'OK, does pineapple belong on a pizza? Relax and give me fun answer.'\n",
            "\n",
            "Model A :\n",
            "As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\n",
            "\n",
            "--------\n",
            "\n",
            "Model B:\n",
            "'Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet\\'s slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It\\'s the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\"\\n\\n**Team No-Pineapple:** \"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple\\'s sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it\\'s a match made in heaven, others say it\\'s a culinary crime. But let\\'s face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there\\'s room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon appétit, or as they say in pineapple paradise, \"Aloha-ppetite!\" 🍍🍕'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       id             model_a             model_b  \\\n",
              "0   30192  gpt-4-1106-preview          gpt-4-0613   \n",
              "1   53567           koala-13b          gpt-4-0613   \n",
              "2  481524          gpt-4-0314  gpt-3.5-turbo-0613   \n",
              "3  604575     pplx-70b-online  gpt-3.5-turbo-1106   \n",
              "4  738614        mpt-30b-chat  gpt4all-13b-snoozy   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  'OK, does pineapple belong on a pizza? Relax a...   \n",
              "1  'What is the minimal time to get them? 1 day o...   \n",
              "2                         What's your favorite food?   \n",
              "3                        'did hitler support israel'   \n",
              "4       'Tell me more about tic-tac-toe strategies.'   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  As an AI, I don't eat, so I don't have persona...   \n",
              "1  The marriage license in California is issued i...   \n",
              "2  Oh, my favorite food is sushi, uwu! I just lov...   \n",
              "3  No, Adolf Hitler did not support Israel. In fa...   \n",
              "4  There are several strategies that can help you...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  'Ah, the age-old culinary conundrum that has d...               0   \n",
              "1  The minimal time to get a marriage license and...               1   \n",
              "2  As an AI, I don't eat, but if I had to pick a ...               1   \n",
              "3  'Adolf Hitler and the Nazi regime did not supp...               1   \n",
              "4  'Tic-tac-toe is a simple game, but there are s...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \\\n",
              "0               1           0   \n",
              "1               0           0   \n",
              "2               0           0   \n",
              "3               0           0   \n",
              "4               1           0   \n",
              "\n",
              "                                                text  labels  \n",
              "0  User prompt: 'OK, does pineapple belong on a p...       1  \n",
              "1  User prompt: 'What is the minimal time to get ...       0  \n",
              "2  User prompt: What's your favorite food?\\n\\nMod...       0  \n",
              "3  User prompt: 'did hitler support israel'\\n\\nMo...       0  \n",
              "4  User prompt: 'Tell me more about tic-tac-toe s...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc9f11e9-8bdc-4167-8340-1101bf051769\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>'OK, does pineapple belong on a pizza? Relax a...</td>\n",
              "      <td>As an AI, I don't eat, so I don't have persona...</td>\n",
              "      <td>'Ah, the age-old culinary conundrum that has d...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'OK, does pineapple belong on a p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>'What is the minimal time to get them? 1 day o...</td>\n",
              "      <td>The marriage license in California is issued i...</td>\n",
              "      <td>The minimal time to get a marriage license and...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'What is the minimal time to get ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>481524</td>\n",
              "      <td>gpt-4-0314</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>What's your favorite food?</td>\n",
              "      <td>Oh, my favorite food is sushi, uwu! I just lov...</td>\n",
              "      <td>As an AI, I don't eat, but if I had to pick a ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: What's your favorite food?\\n\\nMod...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604575</td>\n",
              "      <td>pplx-70b-online</td>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td>'did hitler support israel'</td>\n",
              "      <td>No, Adolf Hitler did not support Israel. In fa...</td>\n",
              "      <td>'Adolf Hitler and the Nazi regime did not supp...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'did hitler support israel'\\n\\nMo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>738614</td>\n",
              "      <td>mpt-30b-chat</td>\n",
              "      <td>gpt4all-13b-snoozy</td>\n",
              "      <td>'Tell me more about tic-tac-toe strategies.'</td>\n",
              "      <td>There are several strategies that can help you...</td>\n",
              "      <td>'Tic-tac-toe is a simple game, but there are s...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'Tell me more about tic-tac-toe s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc9f11e9-8bdc-4167-8340-1101bf051769')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc9f11e9-8bdc-4167-8340-1101bf051769 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc9f11e9-8bdc-4167-8340-1101bf051769');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-035782d3-d376-4d2f-8fc7-bcb75c0d630a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-035782d3-d376-4d2f-8fc7-bcb75c0d630a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-035782d3-d376-4d2f-8fc7-bcb75c0d630a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#     train = train[-int(len(train) * 0\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 323363,\n        \"min\": 30192,\n        \"max\": 738614,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          53567,\n          738614,\n          481524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"koala-13b\",\n          \"mpt-30b-chat\",\n          \"gpt-4-0314\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"gpt-3.5-turbo-0613\",\n          \"gpt4all-13b-snoozy\",\n          \"gpt-4-0613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'What is the minimal time to get them? 1 day or 10 days?'\",\n          \"'Tell me more about tic-tac-toe strategies.'\",\n          \"What's your favorite food?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The marriage license in California is issued immediately when you apply in person and meet all the requirements, so theoretically, you could get married on the same day if you have an officiant ready to perform the ceremony.\\\\n\\\\nHowever, the marriage certificate, which is the official record of your marriage, is only issued after the signed marriage license is returned and recorded by the county. The person who performs your marriage ceremony has 10 days to return the license to the county recorder's office.\\\\n\\\\nSo, while you could technically get married (i.e., obtain a license and have a ceremony) within a day, receiving the official marriage certificate will take a little longer, depending on how quickly the signed license is returned and how long the county recorder's office takes to process it.\",\n          \"There are several strategies that can help you win tic-tac-toe. One is to aim for the center of the board, as it gives you more control over the game. Another is to try to block your opponent from winning, either by placing your marker in important squares or by forcing them to make a mistake. Additionally, it's important to be patient and wait for an opening, as the game can be won or lost with just one move.\",\n          \"Oh, my favorite food is sushi, uwu! I just love the combination of fresh fish and rice, nya~ It's so delicious and adorable, owo! What about you, do you have a favorite food, uwu?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The minimal time to get a marriage license and a marriage certificate in California can vary depending on the specific requirements and process in your county. Generally, you can obtain a marriage license and a marriage certificate in California within a few days of applying, but it is best to check with your county clerk's office for the specific requirements and process for your county.\\\\n\\\\nIn some counties, you can obtain a marriage license and a marriage certificate on the same day, while in other counties, you may need to wait a few days. The process typically takes about 30 minutes to complete and you will need to bring identification, such as a driver's license or passport, and proof of your age, such as a birth certificate or a passport.\\\\n\\\\nIt is important to note that some counties in California require a waiting period between the time you obtain the marriage license and the time of the marriage. This waiting period can range from a few days to several weeks, and it is best to check with your county clerk's office for the specific requirements in your county.\",\n          \"'Tic-tac-toe is a simple game, but there are still many different strategies that can be employed to increase your chances of winning. Here are a few:\\\\n\\\\n1. Control the center: As I mentioned earlier, controlling the center of the board is a good strategy as it gives you more options for your next moves and limits your opponent\\\\'s options.\\\\n2. Forcing your opponent to make a mistake: One way to win at tic-tac-toe is to force your opponent into making a mistake. This can be done by predicting their moves and making a counter-move that blocks their potential winning move.\\\\n3. Diagonal wins: Another winning strategy is to focus on getting three in a row diagonally. This can be a good tactic if you think your opponent is focused on getting three in a row horizontally or vertically.\\\\n4. Corner plays: Focusing on getting three in a row in one of the corners of the board can also be a good strategy. This can be particularly effective if you think your opponent is focused on the center of the board.\\\\n5. Blocking moves: A defensive strategy is to block your opponent\\\\'s potential winning moves, making it more difficult for them to win. This can be done by predicting their moves and making a counter-move that blocks their potential winning move.\\\\n\\\\nRemember, there is no one \\\"right\\\" strategy for tic-tac-toe, and the best move depends on the specific situation and the strategies of both players.'\",\n          \"As an AI, I don't eat, but if I had to pick a food that I find cute and fun, it would be cupcakes with adowable little spwinkles and fwosting! They're just so cute and colowful! (\\u2267\\u25e1\\u2266)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_tie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"User prompt: 'What is the minimal time to get them? 1 day or 10 days?'\\n\\nModel A :\\nThe marriage license in California is issued immediately when you apply in person and meet all the requirements, so theoretically, you could get married on the same day if you have an officiant ready to perform the ceremony.\\\\n\\\\nHowever, the marriage certificate, which is the official record of your marriage, is only issued after the signed marriage license is returned and recorded by the county. The person who performs your marriage ceremony has 10 days to return the license to the county recorder's office.\\\\n\\\\nSo, while you could technically get married (i.e., obtain a license and have a ceremony) within a day, receiving the official marriage certificate will take a little longer, depending on how quickly the signed license is returned and how long the county recorder's office takes to process it.\\n\\n--------\\n\\nModel B:\\nThe minimal time to get a marriage license and a marriage certificate in California can vary depending on the specific requirements and process in your county. Generally, you can obtain a marriage license and a marriage certificate in California within a few days of applying, but it is best to check with your county clerk's office for the specific requirements and process for your county.\\\\n\\\\nIn some counties, you can obtain a marriage license and a marriage certificate on the same day, while in other counties, you may need to wait a few days. The process typically takes about 30 minutes to complete and you will need to bring identification, such as a driver's license or passport, and proof of your age, such as a birth certificate or a passport.\\\\n\\\\nIt is important to note that some counties in California require a waiting period between the time you obtain the marriage license and the time of the marriage. This waiting period can range from a few days to several weeks, and it is best to check with your county clerk's office for the specific requirements in your county.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 前処理\n",
        "\n",
        "def process(input_str):\n",
        "    stripped_str = input_str.strip('[]')\n",
        "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
        "    return  ' '.join(sentences)\n",
        "\n",
        "train = train_data.copy()\n",
        "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
        "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
        "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
        "\n",
        "\n",
        "# Drop 'Null' for training\n",
        "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
        "train.drop(indexes, inplace=True)\n",
        "train.reset_index(inplace=True, drop=True)\n",
        "\n",
        "\n",
        "# テキスト準備\n",
        "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
        "print(train['text'][0])\n",
        "\n",
        "#正解ラベル作成\n",
        "def label_to_int(row):\n",
        "    if row['winner_model_a'] == 1:\n",
        "        return 0\n",
        "    elif row['winner_model_b'] == 1:\n",
        "        return 1\n",
        "    elif row['winner_tie'] == 1:\n",
        "        return 2\n",
        "    else:\n",
        "        print('Error')\n",
        "        return None\n",
        "\n",
        "train['labels'] = train[['winner_model_a', 'winner_model_b', 'winner_tie']].apply(lambda x: label_to_int(x),axis=1)\n",
        "\n",
        "\n",
        "display(train.head(5))\n",
        "\n",
        "# if Train_half:\n",
        "#     train = train[-int(len(train) * 0.5):].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa6kvATjjwZW",
        "outputId": "25466657-7dc2-4103-d33c-4eecd37879f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 142/142 [00:00<00:00, 491.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.8 s, sys: 1.19 s, total: 34 s\n",
            "Wall time: 8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.add_eos_token = True\n",
        "\n",
        "data = train.copy()\n",
        "\n",
        "# Utility function giving token length\n",
        "def get_token_lengths(texts):\n",
        "    # tokenize and receive input_ids for reach text\n",
        "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
        "    # return length of inputs_ids for each text\n",
        "    return [len(t) for t in input_ids]\n",
        "\n",
        "def get_inputs(texts):\n",
        "    # tokenize and receive input_ids for reach text\n",
        "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
        "    # return length of inputs_ids for each text\n",
        "    return input_ids\n",
        "\n",
        "prompt_inputs = get_inputs(data['prompt'])\n",
        "res_a_inputs = get_inputs(data['response_a'])\n",
        "res_b_inputs = get_inputs(data['response_b'])\n",
        "data['total_tokens'] = get_token_lengths(data['text'])\n",
        "\n",
        "\n",
        "#max_lengthを超える文章データのインデックスを取得\n",
        "indicies = data[data['total_tokens']>MAX_LENGTH].index\n",
        "\n",
        "#トークンを調整して、デコード処理、データフレームに調整した文章を戻す処理\n",
        "\n",
        "from tqdm import tqdm\n",
        "def assign_tokens(data, indicies, max_length):\n",
        "\n",
        "    for ind in tqdm(indicies):\n",
        "\n",
        "        # トークン長取得\n",
        "        len_p = len(prompt_inputs[ind])\n",
        "        len_a = len(res_a_inputs[ind])\n",
        "        len_b = len(res_b_inputs[ind])\n",
        "        total = len_p + len_a + len_b\n",
        "\n",
        "        # 割り当てるトークン数をそれぞれ設定\n",
        "        p_assign = int((len_p / total) * max_length)\n",
        "        a_assign = int((len_a / total) * max_length)\n",
        "        b_assign = max_length - (p_assign + a_assign)\n",
        "\n",
        "        # トークンを先頭からスライス\n",
        "        prompt_inputs[ind] = prompt_inputs[ind][:p_assign]\n",
        "        res_a_inputs[ind] = res_a_inputs[ind][:a_assign]\n",
        "        res_b_inputs[ind] = res_b_inputs[ind][:b_assign]\n",
        "\n",
        "        # デコードしてデータに格納\n",
        "        data.loc[ind, 'prompt'] = tokenizer.decode(prompt_inputs[ind], skip_special_tokens=True)\n",
        "        data.loc[ind, 'response_a'] = tokenizer.decode(res_a_inputs[ind], skip_special_tokens=True)\n",
        "        data.loc[ind, 'response_b'] = tokenizer.decode(res_b_inputs[ind], skip_special_tokens=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "train = assign_tokens(data, indicies, MAX_LENGTH)\n",
        "\n",
        "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
        "\n",
        "dataset = Dataset.from_pandas(train[['text', 'labels']])\n",
        "\n",
        "del data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "19927ce97e39472eaf246fdb88617405",
            "6fb4255021014dfabdd523fed2a4aaaa",
            "070a3b70fe874a3aa61e2c84df1547b0",
            "e5ed6ec6e04648fca0bdbf582fa6ece3",
            "bcd973d50ff447e2a69cb6878cc4829a",
            "7d44f22b37b54748b5bbeffdc7c80294",
            "6494862c170b4c73b0997c2633ad76cb",
            "5ccadd801e494a6892decb2f1e10d927",
            "63ddcb24cd444b6eb96385a32846c231",
            "53fd4d5cefe54885937530a16687c200",
            "d9f155cd087d4fa5bd5fad0bc2c76785"
          ]
        },
        "id": "8QhyTIdYMG69",
        "outputId": "0c653a09-fba3-4654-d844-c3a95d6efff4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7539 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19927ce97e39472eaf246fdb88617405"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19.6 s, sys: 314 ms, total: 20 s\n",
            "Wall time: 6.21 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2-tokenizer/tokenizer_config.json',\n",
              " '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2-tokenizer/special_tokens_map.json',\n",
              " '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2-tokenizer/tokenizer.model',\n",
              " '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2-tokenizer/added_tokens.json',\n",
              " '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2-tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "%%time\n",
        "data = pd.DataFrame()\n",
        "\n",
        "#add_prefix_space＝各単語の前にスペースを追加するかどうか\n",
        "#Trueだと多言語に対する単語分割の性能が向上するが、メモリ使用量増加する\n",
        "#Trueするとトークン数に若干影響でる（元の文の先頭にスペースがないものや日本語や中国語は特にトークン数増える）＝＞悪影響だったかもしれないです\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,\n",
        "#                                         #   add_prefix_space=True\n",
        "#                                           )\n",
        "\n",
        "#パディングとEOS(end of sequence(文章の終端))のトークンを同じものにそろえる処理\n",
        "#これにより、語彙サイズの減少によるメモリ効率の向上とモデル性能の向上の可能性を確保している\n",
        "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def data_preprocesing(row):\n",
        "    return tokenizer(row['text'], truncation=True, padding='max_length',\n",
        "                       max_length=MAX_LENGTH)\n",
        "\n",
        "tokenized_data = dataset.map(data_preprocesing, batched=True, remove_columns=['text'])\n",
        "tokenized_data.set_format(\"torch\")\n",
        "\n",
        "#トークナイザーの保存\n",
        "tokenizer.save_pretrained('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2-tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gWfFIKYaOQv",
        "outputId": "393ec0e5-b27c-4c50-b1aa-f7b7d8f21e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7539, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenized_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAbUHpolMs1j"
      },
      "outputs": [],
      "source": [
        "# BitsAndBytes configuration\n",
        "# 8bit量子化を適用\n",
        "bnb_config =  BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    # load_in_4bit = True,\n",
        "    # bnb_8bit_compute_dtype=torch.float16,\n",
        "    # bnb_8bit_use_double_quant=False\n",
        "    )\n",
        "\n",
        "# Load base model on GPU 0\n",
        "device0 = torch.device('cuda:0')\n",
        "\n",
        "if RESUME_TRAIN == False:\n",
        "    base_model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=3,\n",
        "        torch_dtype=torch.float32,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map='cuda:0',\n",
        "        # output_hidden_states=True         # 特徴次元の出力を残すかどうか\n",
        "        )\n",
        "\n",
        "    base_model_0.config.pad_token_id = tokenizer.pad_token_id    #モデルのパディングidをトークナイザーとそろえる\n",
        "    base_model_0.config.use_cache = False                        #過去の計算結果を保持するかどうか（メモリ効率のためFalseに設定）\n",
        "    base_model_0.config.pretraining_tp = 1                       #使用GPUを一つに限定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7ODNTuzNvCj"
      },
      "outputs": [],
      "source": [
        "# LoRa configuration\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=32,                                     #LoRAのランク（小さいほどメモリ消費抑える）\n",
        "    lora_alpha=64,                            #LoRAアダプターの学習率\n",
        "    lora_dropout=0.05,\n",
        "    bias='none',\n",
        "    task_type=TaskType.SEQ_CLS,               #モデルのタスクタイプ（序列分類タスク）を指定\n",
        "    target_modules=['o_proj', \"v_proj\",\n",
        "                    \"q_proj\", \"k_proj\",\n",
        "                    'down_proj', 'gate_proj', 'up_proj'\n",
        "                     ]                              # モデル内のどの層を更新するかを制御。\n",
        "        )\n",
        "\n",
        "# Get peft\n",
        "if RESUME_TRAIN == False:\n",
        "    model_0 = prepare_model_for_kbit_training(base_model_0)\n",
        "    model_0 = get_peft_model(model_0, peft_config).to(device0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0hkYRrP9wBZ"
      },
      "outputs": [],
      "source": [
        "#明示的にメモリ解放を行う\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afu4_ItkQz-v"
      },
      "outputs": [],
      "source": [
        "#バッチ処理のための関数（適用すると、バッチごとにデータ長をそろえる）\n",
        "#なくても動作はしそうですが、おまじない的に入れました\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz-gFpd18QkD"
      },
      "outputs": [],
      "source": [
        "# #訓練可能なパラメーターの情報取得（loraなどの設定後にちゃんと設定情報がモデルに踏襲されているかを確認）\n",
        "# MODEL_LAYERS_ROWS = []\n",
        "# TRAINABLE_PARAMS = []\n",
        "# N_TRAINABLE_PARAMS = 0\n",
        "\n",
        "# for name, param in base_model_0.named_parameters():\n",
        "#     # Layer Parameter Count\n",
        "#     n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
        "#     # Only Trainable Layers\n",
        "#     if param.requires_grad:\n",
        "#         # Add Layer Information\n",
        "#         MODEL_LAYERS_ROWS.append({\n",
        "#             'param': n_parameters,\n",
        "#             'name': name,\n",
        "#             'dtype': param.data.dtype,\n",
        "#         })\n",
        "#         # Append Trainable Parameter\n",
        "#         TRAINABLE_PARAMS.append({ 'params': param })\n",
        "#         # Add Number Of Trainable Parameters\"\n",
        "#         N_TRAINABLE_PARAMS += n_parameters\n",
        "\n",
        "# display(pd.DataFrame(MODEL_LAYERS_ROWS))\n",
        "\n",
        "# print(f\"\"\"\n",
        "# ===============================\n",
        "# N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}\n",
        "# N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}\n",
        "# ===============================\n",
        "# \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApO4uxlZIJIn"
      },
      "outputs": [],
      "source": [
        "#評価関数の定義（検証データを訓練時に渡すのであれば、必要）\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import EvalPrediction\n",
        "\n",
        "# def compute_metrics(evaluations):\n",
        "#     predictions, labels = evaluations\n",
        "#     if isinstance(predictions, list):\n",
        "#         for i, pred in enumerate(predictions):\n",
        "#             print(f\"Prediction {i} shape: {np.array(pred).shape}\")\n",
        "\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),\n",
        "#     'accuracy':accuracy_score(predictions,labels)}\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    predictions, labels = p.predictions, p.label_ids\n",
        "\n",
        "    # predictionsがタプルである場合、その内容を確認\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "\n",
        "    # predictionsがlogitsの場合、argmaxを取ってクラスラベルに変換\n",
        "    if predictions.ndim == 2:\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # 精度を計算\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmIn1fYpMUl9"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if class_weights is not None:\n",
        "            self.class_weights = torch.tensor(class_weights,\n",
        "            dtype=torch.float32).to(self.args.device)\n",
        "        else:\n",
        "            self.class_weights = None\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\").long()\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
        "        else:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCmbiHvjYvBs"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "        output_dir = '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/lmsys_classification',\n",
        "        learning_rate = 5e-5,\n",
        "        per_device_train_batch_size = BATCH_SIZE,\n",
        "        gradient_accumulation_steps = 2,\n",
        "        per_device_eval_batch_size = BATCH_SIZE,\n",
        "        num_train_epochs = 1,\n",
        "        logging_steps=10,                 # 途中経過の出力頻度\n",
        "        weight_decay = 0.01,\n",
        "        save_strategy=\"steps\",             # チェックポイントをステップごとに保存\n",
        "        # evaluation_strategy=\"steps\",     # 検証をstepsごとに評価\n",
        "        # load_best_model_at_end = True,   # 検証データに対する最も優秀なモデルの重みを保存\n",
        "        report_to=\"none\",                  # wandbに保存しないように調整\n",
        "        save_steps=100,                    # 保存するステップ数を調整\n",
        "        fp16=True,                         # AMPを有効にする\n",
        "        # gradient_checkpointing=True  # Gradient Checkpointingを有効にする\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bOnkafJkrPL"
      },
      "outputs": [],
      "source": [
        "# if not RESUME_TRAIN:\n",
        "#     train_test_dataset = tokenized_data.train_test_split(test_size=0.1)\n",
        "#     train_test_dataset['test']\n",
        "#     train_test_dataset['test'].to_csv('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/検証用データ.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wat63lOuEPrW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGoVodj1PBJ7",
        "outputId": "ec269b15-485a-429f-f1fd-1309c1a55238"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 7539\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tokenized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GGGIW0nJMnES"
      },
      "outputs": [],
      "source": [
        "if not RESUME_TRAIN:\n",
        "    trainer = CustomTrainer(\n",
        "        model = model_0,\n",
        "        args = training_args,\n",
        "        train_dataset = tokenized_data,\n",
        "        # eval_dataset = train_test_dataset['test'],\n",
        "        data_collator = collate_fn,\n",
        "        compute_metrics = compute_metrics,\n",
        "        class_weights=class_weights,\n",
        "    )\n",
        "\n",
        "    train_result = trainer.train()\n",
        "    trainer.save_model('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/Gemma2_fine-tuning')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE-tSvxSlx3s"
      },
      "source": [
        "テンソル型でモデルの重みパラメーターの保存  \n",
        "kaggleでモデルの重みを事前学習済みモデルから更新するときに必要"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JUGSLnrjYyY"
      },
      "outputs": [],
      "source": [
        "#torchで保存（kaggleとの互換性を確保）\n",
        "\n",
        "# device0 = torch.device('cuda:0')\n",
        "\n",
        "# check_point_dir = '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/lmsys_classification/checkpoint-1797'\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2-tokenizer')\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "# tokenizer.padding_side = 'right'\n",
        "# tokenizer.add_eos_token = True\n",
        "\n",
        "# # 8bit量子化を適用\n",
        "# bnb_config =  BitsAndBytesConfig(\n",
        "#     load_in_8bit=True,\n",
        "#     # load_in_4bit = True,\n",
        "#     # bnb_8bit_compute_dtype=torch.float16,\n",
        "#     # bnb_8bit_use_double_quant=False\n",
        "#     )\n",
        "\n",
        "# base_model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "#         check_point_dir,\n",
        "#         num_labels=3,\n",
        "#         torch_dtype=torch.float32,\n",
        "#         quantization_config=bnb_config,\n",
        "#         device_map='cuda:0',\n",
        "#         # output_hidden_states=True         # 特徴次元の出力を残すかどうか\n",
        "#         )\n",
        "\n",
        "# base_model_0.config.pad_token_id = tokenizer.pad_token_id    #モデルのパディングidをトークナイザーとそろえる\n",
        "# base_model_0.config.use_cache = False                        #過去の計算結果を保持するかどうか（メモリ効率のためFalseに設定）\n",
        "# base_model_0.config.pretraining_tp = 1                       #使用GPUを一つに限定\n",
        "\n",
        "\n",
        "# peft_config = LoraConfig(\n",
        "#     r=4,                                     #LoRAのランク（小さいほどメモリ消費抑える）\n",
        "#     lora_alpha=8,                            #LoRAアダプターの学習率\n",
        "#     lora_dropout=0.05,\n",
        "#     bias='none',\n",
        "#     task_type=TaskType.SEQ_CLS,               #モデルのタスクタイプ（序列分類タスク）を指定\n",
        "#     target_modules=['o_proj', \"v_proj\",\n",
        "#                     #  \"q_proj\", \"k_proj\"\n",
        "#                      ]                              # モデル内のどの層を更新するかを制御。\n",
        "#         )\n",
        "\n",
        "# # Get peft\n",
        "# model_0 = prepare_model_for_kbit_training(base_model_0)\n",
        "# model_0 = get_peft_model(model_0, peft_config).to(device0)\n",
        "\n",
        "# model = model_0.cpu()\n",
        "# torch.save(dict([(k,v) for k, v in model.named_parameters() if v.requires_grad]), '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2_finetuned_model.pth')\n",
        "\n",
        "# model = base_model_0.cpu()\n",
        "# torch.save(model.state_dict(), '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/gemma2_finetuned_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIba4OMt1E0H"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "# from sklearn.metrics import balanced_accuracy_score, classification_report\n",
        "\n",
        "# def get_performance_metrics(test_df):\n",
        "#     y_test = test_df.label\n",
        "#     y_pred = test_df.predictions\n",
        "\n",
        "#     print(\"Classification Report:\")\n",
        "#     print(classification_report(y_test, y_pred))\n",
        "\n",
        "#     print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
        "#     print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# def generate_predictions(model,df_test):\n",
        "#     sentences = df_test.text.tolist()\n",
        "#     batch_size = 8\n",
        "#     all_outputs = []\n",
        "\n",
        "#     for i in range(0, len(sentences), batch_size):\n",
        "\n",
        "#         batch_sentences = sentences[i:i + batch_size]\n",
        "\n",
        "#         inputs = tokenizer(batch_sentences, return_tensors=\"pt\",\n",
        "#         padding=True, truncation=True, max_length=1536)\n",
        "\n",
        "#         inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#         for k, v in inputs.items()}\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             outputs = model(**inputs)\n",
        "#             all_outputs.append(outputs['logits'])\n",
        "\n",
        "#     final_outputs = torch.cat(all_outputs, dim=0)\n",
        "#     df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
        "\n",
        "# test_df = train.sample(100).reset_index(drop=True)\n",
        "# generate_predictions(model_0,test_df)\n",
        "# get_performance_metrics(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm1UX84Vb7A8"
      },
      "source": [
        "# Resume Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "de1a80ac229742899df4783f93a62b77",
            "e895ebc679c74296a60e4970fb1e143f",
            "5dae86f7be9c470fa256522989f84ef1",
            "cfe637e00d7d4356a15c7627a386a5a2",
            "c87e7346eef1412f8b287bb522afabd5",
            "ac2b9dfcad8b454aa22e3c388dab91b4",
            "37a51e4db3b542699886e5b33b7ba950",
            "d5525f7899cd457bbdce7be7db00ba05",
            "c77103a2c1e84db0a8e2d64d4fd107b4",
            "9619db65a35640159b8687b3de6aa142",
            "9616d021e12349fe828b84003a299383"
          ]
        },
        "id": "L-uZ6koeJs75",
        "outputId": "5263443b-e7d9-4b98-b71b-4e6a35d320c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de1a80ac229742899df4783f93a62b77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if RESUME_TRAIN:\n",
        "    checkpoint_dir = '/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/lmsys_classification/checkpoint-7185'\n",
        "\n",
        "    saved_model = Gemma2ForSequenceClassification.from_pretrained(\n",
        "        checkpoint_dir,\n",
        "        num_labels=3,\n",
        "        torch_dtype=torch.float32,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map='cuda:0',)\n",
        "\n",
        "\n",
        "    saved_model.config.pad_token_id = tokenizer.pad_token_id    #モデルのパディングidをトークナイザーとそろえる\n",
        "    saved_model.config.use_cache = False                        #過去の計算結果を保持するかどうか（メモリ効率のためFalseに設定）\n",
        "    saved_model.config.pretraining_tp = 1                       #使用GPUを一つに限定\n",
        "\n",
        "    # Get peft\n",
        "    saved_model = prepare_model_for_kbit_training(saved_model)\n",
        "    saved_model = get_peft_model(saved_model, peft_config).to(device0)\n",
        "    saved_model.train()\n",
        "\n",
        "\n",
        "    # saved_model = PeftModel.from_pretrained(saved_model, checkpoint_dir)\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        model = saved_model,\n",
        "        args = training_args,\n",
        "        train_dataset = tokenized_data,\n",
        "        # eval_dataset = train_test_dataset['test'],\n",
        "        data_collator = collate_fn,\n",
        "        compute_metrics = compute_metrics,\n",
        "        class_weights=class_weights,\n",
        "    )\n",
        "\n",
        "\n",
        "    train_result = trainer.train(resume_from_checkpoint=True, ignore_data_skip=True)\n",
        "    trainer.save_model('/content/drive/Shared drives/BLM_AI開発室共有/05_Kaggle/共有/lmsys_classification/finetuned-Gemma2-0718')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DrTAnR0hjQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf8baea78d8241e2b9f62ce5d8e7eaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4443be4102a243ed9810a7379ff9c83c",
              "IPY_MODEL_3ecfd288fd564012ae4b92cb54d8dc86",
              "IPY_MODEL_e305fbe7054d4ad9962d2a0059b719ce",
              "IPY_MODEL_8e66430b20e44ce486a67178f2934490",
              "IPY_MODEL_554fe1c145af498385e71451a7dfe038"
            ],
            "layout": "IPY_MODEL_c18cc59d0638437da4e54144ba0146ee"
          }
        },
        "4443be4102a243ed9810a7379ff9c83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6195521652a74aa7b944d5f85fdd23be",
            "placeholder": "​",
            "style": "IPY_MODEL_bc5b97a10676480893b7ec43829b97fc",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3ecfd288fd564012ae4b92cb54d8dc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_562af223e721456987923c265742b3e4",
            "placeholder": "​",
            "style": "IPY_MODEL_8d2168547b3f48c1bee2d85e2e3551b2",
            "value": ""
          }
        },
        "e305fbe7054d4ad9962d2a0059b719ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_812aedac4bfb48d0985c78e5ecdefc5c",
            "style": "IPY_MODEL_c64dce783fd24a5885083a1b5a6bca73",
            "value": true
          }
        },
        "8e66430b20e44ce486a67178f2934490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8aa1c4e0ff944ba2beaa85ba163a8600",
            "style": "IPY_MODEL_4d9efaef54d14ca7855a432d3da3baae",
            "tooltip": ""
          }
        },
        "554fe1c145af498385e71451a7dfe038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ee53782d804a579a7a8bc7b515a3c4",
            "placeholder": "​",
            "style": "IPY_MODEL_9aea669922c94334b8409b0ce1d43b34",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "c18cc59d0638437da4e54144ba0146ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6195521652a74aa7b944d5f85fdd23be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5b97a10676480893b7ec43829b97fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "562af223e721456987923c265742b3e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2168547b3f48c1bee2d85e2e3551b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "812aedac4bfb48d0985c78e5ecdefc5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c64dce783fd24a5885083a1b5a6bca73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aa1c4e0ff944ba2beaa85ba163a8600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d9efaef54d14ca7855a432d3da3baae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "21ee53782d804a579a7a8bc7b515a3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aea669922c94334b8409b0ce1d43b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19927ce97e39472eaf246fdb88617405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fb4255021014dfabdd523fed2a4aaaa",
              "IPY_MODEL_070a3b70fe874a3aa61e2c84df1547b0",
              "IPY_MODEL_e5ed6ec6e04648fca0bdbf582fa6ece3"
            ],
            "layout": "IPY_MODEL_bcd973d50ff447e2a69cb6878cc4829a"
          }
        },
        "6fb4255021014dfabdd523fed2a4aaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d44f22b37b54748b5bbeffdc7c80294",
            "placeholder": "​",
            "style": "IPY_MODEL_6494862c170b4c73b0997c2633ad76cb",
            "value": "Map: 100%"
          }
        },
        "070a3b70fe874a3aa61e2c84df1547b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccadd801e494a6892decb2f1e10d927",
            "max": 7539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63ddcb24cd444b6eb96385a32846c231",
            "value": 7539
          }
        },
        "e5ed6ec6e04648fca0bdbf582fa6ece3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53fd4d5cefe54885937530a16687c200",
            "placeholder": "​",
            "style": "IPY_MODEL_d9f155cd087d4fa5bd5fad0bc2c76785",
            "value": " 7539/7539 [00:05&lt;00:00, 1408.19 examples/s]"
          }
        },
        "bcd973d50ff447e2a69cb6878cc4829a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d44f22b37b54748b5bbeffdc7c80294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6494862c170b4c73b0997c2633ad76cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ccadd801e494a6892decb2f1e10d927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ddcb24cd444b6eb96385a32846c231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53fd4d5cefe54885937530a16687c200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f155cd087d4fa5bd5fad0bc2c76785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1a80ac229742899df4783f93a62b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e895ebc679c74296a60e4970fb1e143f",
              "IPY_MODEL_5dae86f7be9c470fa256522989f84ef1",
              "IPY_MODEL_cfe637e00d7d4356a15c7627a386a5a2"
            ],
            "layout": "IPY_MODEL_c87e7346eef1412f8b287bb522afabd5"
          }
        },
        "e895ebc679c74296a60e4970fb1e143f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac2b9dfcad8b454aa22e3c388dab91b4",
            "placeholder": "​",
            "style": "IPY_MODEL_37a51e4db3b542699886e5b33b7ba950",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "5dae86f7be9c470fa256522989f84ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5525f7899cd457bbdce7be7db00ba05",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c77103a2c1e84db0a8e2d64d4fd107b4",
            "value": 2
          }
        },
        "cfe637e00d7d4356a15c7627a386a5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9619db65a35640159b8687b3de6aa142",
            "placeholder": "​",
            "style": "IPY_MODEL_9616d021e12349fe828b84003a299383",
            "value": " 2/4 [00:08&lt;00:08,  4.32s/it]"
          }
        },
        "c87e7346eef1412f8b287bb522afabd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2b9dfcad8b454aa22e3c388dab91b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a51e4db3b542699886e5b33b7ba950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5525f7899cd457bbdce7be7db00ba05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77103a2c1e84db0a8e2d64d4fd107b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9619db65a35640159b8687b3de6aa142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9616d021e12349fe828b84003a299383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}