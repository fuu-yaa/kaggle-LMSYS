{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NWqHVgg-Mk5",
        "outputId": "4862b9da-4a12-4f5e-b9ab-912f37278f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SLGhVdp1-uiz",
        "outputId": "a0a84b35-f822-4538-aa02-d1a748a73c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.42.3 in /usr/local/lib/python3.10/dist-packages (4.42.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.3) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.3) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.3) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.3) (2024.7.4)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers==4.42.3\n",
        "!pip install -U tokenizers\n",
        "!pip install -U peft\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U datasets\n",
        "\n",
        "#„Ç®„É©„Éº„ÅåÂá∫„Åü„ÅÆ„Åß„ÄÅ‰∏ãË®ò„ÅÆ„Éê„Éº„Ç∏„Éß„É≥„Å´„ÉÄ„Ç¶„É≥„Ç∞„É¨„Éº„Éâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYxzW6uKEloj"
      },
      "outputs": [],
      "source": [
        "# #tensorflow„ÅßTPU„ÇíÂãï„Åã„ÅôÔºÅ\n",
        "\n",
        "# %tensorflow_version 2.x\n",
        "# import tensorflow as tf\n",
        "# print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# try:\n",
        "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#     print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#     raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BemQYfF4Ar05",
        "outputId": "90b30b51-40fa-4b5b-b3d6-3d42e6fe3b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers: 4.42.3\n",
            "tokenizers: 0.19.1\n",
            "peft: 0.11.1\n",
            "Name: bitsandbytes\n",
            "Version: 0.43.1\n",
            "Summary: k-bit optimizers and matrix multiplication routines.\n",
            "Home-page: https://github.com/TimDettmers/bitsandbytes\n",
            "Author: Tim Dettmers\n",
            "Author-email: dettmers@cs.washington.edu\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, torch\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import transformers\n",
        "import tokenizers\n",
        "import peft\n",
        "import bitsandbytes\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "from transformers import Gemma2ForSequenceClassification\n",
        "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from torch.cuda.amp import autocast\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import DatasetDict, Dataset\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# „É©„Ç§„Éñ„É©„É™„Éº„ÅÆ„Éê„Éº„Ç∏„Éß„É≥Á¢∫Ë™ç\n",
        "print(f\"transformers: {transformers.__version__}\")\n",
        "print(f\"tokenizers: {tokenizers.__version__}\")\n",
        "print(f\"peft: {peft.__version__}\")\n",
        "# print(f\"bitsandbytes: {bitsandbytes.__version__}\")      # „Éê„Éº„Ç∏„Éß„É≥Âè§„ÅÑ„Å®„Ç®„É©„ÉºÂá∫„Çã\n",
        "!pip show BitsAndBytes\n",
        "\n",
        "#ÊºîÁÆó‰∏≠„ÅÆ„É°„É¢„É™„Ç¢„Ç¶„Éà„ÅåËß£Ê±∫„Åó„Å™„ÅÑÂ†¥Âêà„ÄÅTrue„Å´Â§âÊõ¥\n",
        "#ÂçäÁ≤æÂ∫¶ÊºîÁÆó\n",
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "#„Éï„É©„ÉÉ„Ç∑„É•ÂçäÁ≤æÂ∫¶ÊºîÁÆó(„Çà„Çä„É°„É¢„É™ÂäπÁéáÈáçË¶ñ)\n",
        "torch.backends.cuda.enable_flash_sdp(False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394,
          "referenced_widgets": [
            "cf8baea78d8241e2b9f62ce5d8e7eaf2",
            "4443be4102a243ed9810a7379ff9c83c",
            "3ecfd288fd564012ae4b92cb54d8dc86",
            "e305fbe7054d4ad9962d2a0059b719ce",
            "8e66430b20e44ce486a67178f2934490",
            "554fe1c145af498385e71451a7dfe038",
            "c18cc59d0638437da4e54144ba0146ee",
            "6195521652a74aa7b944d5f85fdd23be",
            "bc5b97a10676480893b7ec43829b97fc",
            "562af223e721456987923c265742b3e4",
            "8d2168547b3f48c1bee2d85e2e3551b2",
            "812aedac4bfb48d0985c78e5ecdefc5c",
            "c64dce783fd24a5885083a1b5a6bca73",
            "8aa1c4e0ff944ba2beaa85ba163a8600",
            "4d9efaef54d14ca7855a432d3da3baae",
            "21ee53782d804a579a7a8bc7b515a3c4",
            "9aea669922c94334b8409b0ce1d43b34"
          ]
        },
        "id": "zmsD7Dhsr6SN",
        "outputId": "bfa0227f-6ffd-45b5-9a96-d2cc87802a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface_huba (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface_huba\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf8baea78d8241e2b9f62ce5d8e7eaf2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#‰∫ãÂâçÂ≠¶ÁøíÊ∏à„ÅøGemma2„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø„Å´Huggingface„Å∏„ÅÆ„É≠„Ç∞„Ç§„É≥„ÅåÂøÖË¶Å\n",
        "\n",
        "!pip install huggingface_huba\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Kt2_xhAu9Q",
        "outputId": "4370fc9f-c9d7-46ad-99b8-ca18a7515b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57477, 9)\n",
            "Resume training setting\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/train.csv')\n",
        "columns = train_data.columns\n",
        "print(train_data.shape)\n",
        "# Ultrafeedback_data = pd.read_csv('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/ultrafeedback_chosen_ver2.csv')\n",
        "# Ultrafeedback_data = Ultrafeedback_data[train_data.columns]\n",
        "\n",
        "MODEL_NAME = 'google/gemma-2-9b-it'\n",
        "\n",
        "MAX_LENGTH = 1536\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "class_weights = None    #„ÇØ„É©„Çπ„ÅÆÂàÜÂ∏É„ÇíËÄÉÊÖÆ„Åó„Åü„ÅÑ„Å®„Åç„ÅÆÈáçË¶ÅÂ∫¶„ÅÆÂ§âÊï∞Ôºà‰ªäÂõû„ÅØÂàÜÂ∏É„Åå„Åª„ÅºÂùá‰∏Ä„Å™„ÅÆ„Åß„ÄÅNone„Å´Ë®≠ÂÆöÔºâ\n",
        "TEST_MODE = False      #Âãï‰ΩúÊ§úË®ºÁî®„ÅÆ„Éï„É©„Ç∞Â§âÊï∞\n",
        "Train_half = False    #ÂçäÂàÜ„ÅßË®ìÁ∑¥ÔºàÁ≤æÂ∫¶Ê§úË®ºÔºâ\n",
        "RESUME_TRAIN = False   #„É¢„Éá„É´„ÅÆÂÜçË®ìÁ∑¥„ÅÆ„Åü„ÇÅ„ÅÆ„Éï„É©„Ç∞Â§âÊï∞\n",
        "\n",
        "#„Çπ„É¢„Éº„É´„Çπ„Çø„Éº„Éà\n",
        "if TEST_MODE:\n",
        "    train_data = train_data.iloc[-1000:,:].reset_index(drop=True)\n",
        "\n",
        "if RESUME_TRAIN:\n",
        "    checkpoint_dir = '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/lmsys_classification/checkpoint-7185'\n",
        "    print('Resume training setting')\n",
        "    # train_data = pd.concat([train_data, Ultrafeedback_data], axis=0).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFYlVegrsvSk"
      },
      "outputs": [],
      "source": [
        "#kaggle API„Çí‰Ωø„Å£„Å¶Llama3„É¢„Éá„É´„ÅÆ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø„ÇíË°å„ÅÜÔºà‰∫íÊèõÊÄß„ÇíÁ¢∫‰øùÔºâ\n",
        "\n",
        "# from google.colab import files\n",
        "# files.upload()\n",
        "\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !pip install kaggle\n",
        "\n",
        "# import kagglehub\n",
        "\n",
        "# # Download latest version\n",
        "# path = kagglehub.model_download(\"metaresearch/llama-3/transformers/8b-chat-hf\")\n",
        "\n",
        "# print(\"Path to model files:\", path)\n",
        "\n",
        "# !cp -r {path} '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/Llama3_basemodel'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "DII1FhI6MCse",
        "outputId": "f45e01c2-ec00-4d50-f719-ae0a8582eea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User prompt: 'OK, does pineapple belong on a pizza? Relax and give me fun answer.'\n",
            "\n",
            "Model A :\n",
            "As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\n",
            "\n",
            "--------\n",
            "\n",
            "Model B:\n",
            "'Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet\\'s slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It\\'s the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\"\\n\\n**Team No-Pineapple:** \"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple\\'s sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it\\'s a match made in heaven, others say it\\'s a culinary crime. But let\\'s face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there\\'s room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app√©tit, or as they say in pineapple paradise, \"Aloha-ppetite!\" üççüçï'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       id             model_a             model_b  \\\n",
              "0   30192  gpt-4-1106-preview          gpt-4-0613   \n",
              "1   53567           koala-13b          gpt-4-0613   \n",
              "2  481524          gpt-4-0314  gpt-3.5-turbo-0613   \n",
              "3  604575     pplx-70b-online  gpt-3.5-turbo-1106   \n",
              "4  738614        mpt-30b-chat  gpt4all-13b-snoozy   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  'OK, does pineapple belong on a pizza? Relax a...   \n",
              "1  'What is the minimal time to get them? 1 day o...   \n",
              "2                         What's your favorite food?   \n",
              "3                        'did hitler support israel'   \n",
              "4       'Tell me more about tic-tac-toe strategies.'   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  As an AI, I don't eat, so I don't have persona...   \n",
              "1  The marriage license in California is issued i...   \n",
              "2  Oh, my favorite food is sushi, uwu! I just lov...   \n",
              "3  No, Adolf Hitler did not support Israel. In fa...   \n",
              "4  There are several strategies that can help you...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  'Ah, the age-old culinary conundrum that has d...               0   \n",
              "1  The minimal time to get a marriage license and...               1   \n",
              "2  As an AI, I don't eat, but if I had to pick a ...               1   \n",
              "3  'Adolf Hitler and the Nazi regime did not supp...               1   \n",
              "4  'Tic-tac-toe is a simple game, but there are s...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \\\n",
              "0               1           0   \n",
              "1               0           0   \n",
              "2               0           0   \n",
              "3               0           0   \n",
              "4               1           0   \n",
              "\n",
              "                                                text  labels  \n",
              "0  User prompt: 'OK, does pineapple belong on a p...       1  \n",
              "1  User prompt: 'What is the minimal time to get ...       0  \n",
              "2  User prompt: What's your favorite food?\\n\\nMod...       0  \n",
              "3  User prompt: 'did hitler support israel'\\n\\nMo...       0  \n",
              "4  User prompt: 'Tell me more about tic-tac-toe s...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc9f11e9-8bdc-4167-8340-1101bf051769\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>'OK, does pineapple belong on a pizza? Relax a...</td>\n",
              "      <td>As an AI, I don't eat, so I don't have persona...</td>\n",
              "      <td>'Ah, the age-old culinary conundrum that has d...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'OK, does pineapple belong on a p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>'What is the minimal time to get them? 1 day o...</td>\n",
              "      <td>The marriage license in California is issued i...</td>\n",
              "      <td>The minimal time to get a marriage license and...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'What is the minimal time to get ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>481524</td>\n",
              "      <td>gpt-4-0314</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>What's your favorite food?</td>\n",
              "      <td>Oh, my favorite food is sushi, uwu! I just lov...</td>\n",
              "      <td>As an AI, I don't eat, but if I had to pick a ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: What's your favorite food?\\n\\nMod...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604575</td>\n",
              "      <td>pplx-70b-online</td>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td>'did hitler support israel'</td>\n",
              "      <td>No, Adolf Hitler did not support Israel. In fa...</td>\n",
              "      <td>'Adolf Hitler and the Nazi regime did not supp...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'did hitler support israel'\\n\\nMo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>738614</td>\n",
              "      <td>mpt-30b-chat</td>\n",
              "      <td>gpt4all-13b-snoozy</td>\n",
              "      <td>'Tell me more about tic-tac-toe strategies.'</td>\n",
              "      <td>There are several strategies that can help you...</td>\n",
              "      <td>'Tic-tac-toe is a simple game, but there are s...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>User prompt: 'Tell me more about tic-tac-toe s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc9f11e9-8bdc-4167-8340-1101bf051769')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc9f11e9-8bdc-4167-8340-1101bf051769 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc9f11e9-8bdc-4167-8340-1101bf051769');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-035782d3-d376-4d2f-8fc7-bcb75c0d630a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-035782d3-d376-4d2f-8fc7-bcb75c0d630a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-035782d3-d376-4d2f-8fc7-bcb75c0d630a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#     train = train[-int(len(train) * 0\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 323363,\n        \"min\": 30192,\n        \"max\": 738614,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          53567,\n          738614,\n          481524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"koala-13b\",\n          \"mpt-30b-chat\",\n          \"gpt-4-0314\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"gpt-3.5-turbo-0613\",\n          \"gpt4all-13b-snoozy\",\n          \"gpt-4-0613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'What is the minimal time to get them? 1 day or 10 days?'\",\n          \"'Tell me more about tic-tac-toe strategies.'\",\n          \"What's your favorite food?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The marriage license in California is issued immediately when you apply in person and meet all the requirements, so theoretically, you could get married on the same day if you have an officiant ready to perform the ceremony.\\\\n\\\\nHowever, the marriage certificate, which is the official record of your marriage, is only issued after the signed marriage license is returned and recorded by the county. The person who performs your marriage ceremony has 10 days to return the license to the county recorder's office.\\\\n\\\\nSo, while you could technically get married (i.e., obtain a license and have a ceremony) within a day, receiving the official marriage certificate will take a little longer, depending on how quickly the signed license is returned and how long the county recorder's office takes to process it.\",\n          \"There are several strategies that can help you win tic-tac-toe. One is to aim for the center of the board, as it gives you more control over the game. Another is to try to block your opponent from winning, either by placing your marker in important squares or by forcing them to make a mistake. Additionally, it's important to be patient and wait for an opening, as the game can be won or lost with just one move.\",\n          \"Oh, my favorite food is sushi, uwu! I just love the combination of fresh fish and rice, nya~ It's so delicious and adorable, owo! What about you, do you have a favorite food, uwu?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The minimal time to get a marriage license and a marriage certificate in California can vary depending on the specific requirements and process in your county. Generally, you can obtain a marriage license and a marriage certificate in California within a few days of applying, but it is best to check with your county clerk's office for the specific requirements and process for your county.\\\\n\\\\nIn some counties, you can obtain a marriage license and a marriage certificate on the same day, while in other counties, you may need to wait a few days. The process typically takes about 30 minutes to complete and you will need to bring identification, such as a driver's license or passport, and proof of your age, such as a birth certificate or a passport.\\\\n\\\\nIt is important to note that some counties in California require a waiting period between the time you obtain the marriage license and the time of the marriage. This waiting period can range from a few days to several weeks, and it is best to check with your county clerk's office for the specific requirements in your county.\",\n          \"'Tic-tac-toe is a simple game, but there are still many different strategies that can be employed to increase your chances of winning. Here are a few:\\\\n\\\\n1. Control the center: As I mentioned earlier, controlling the center of the board is a good strategy as it gives you more options for your next moves and limits your opponent\\\\'s options.\\\\n2. Forcing your opponent to make a mistake: One way to win at tic-tac-toe is to force your opponent into making a mistake. This can be done by predicting their moves and making a counter-move that blocks their potential winning move.\\\\n3. Diagonal wins: Another winning strategy is to focus on getting three in a row diagonally. This can be a good tactic if you think your opponent is focused on getting three in a row horizontally or vertically.\\\\n4. Corner plays: Focusing on getting three in a row in one of the corners of the board can also be a good strategy. This can be particularly effective if you think your opponent is focused on the center of the board.\\\\n5. Blocking moves: A defensive strategy is to block your opponent\\\\'s potential winning moves, making it more difficult for them to win. This can be done by predicting their moves and making a counter-move that blocks their potential winning move.\\\\n\\\\nRemember, there is no one \\\"right\\\" strategy for tic-tac-toe, and the best move depends on the specific situation and the strategies of both players.'\",\n          \"As an AI, I don't eat, but if I had to pick a food that I find cute and fun, it would be cupcakes with adowable little spwinkles and fwosting! They're just so cute and colowful! (\\u2267\\u25e1\\u2266)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_tie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"User prompt: 'What is the minimal time to get them? 1 day or 10 days?'\\n\\nModel A :\\nThe marriage license in California is issued immediately when you apply in person and meet all the requirements, so theoretically, you could get married on the same day if you have an officiant ready to perform the ceremony.\\\\n\\\\nHowever, the marriage certificate, which is the official record of your marriage, is only issued after the signed marriage license is returned and recorded by the county. The person who performs your marriage ceremony has 10 days to return the license to the county recorder's office.\\\\n\\\\nSo, while you could technically get married (i.e., obtain a license and have a ceremony) within a day, receiving the official marriage certificate will take a little longer, depending on how quickly the signed license is returned and how long the county recorder's office takes to process it.\\n\\n--------\\n\\nModel B:\\nThe minimal time to get a marriage license and a marriage certificate in California can vary depending on the specific requirements and process in your county. Generally, you can obtain a marriage license and a marriage certificate in California within a few days of applying, but it is best to check with your county clerk's office for the specific requirements and process for your county.\\\\n\\\\nIn some counties, you can obtain a marriage license and a marriage certificate on the same day, while in other counties, you may need to wait a few days. The process typically takes about 30 minutes to complete and you will need to bring identification, such as a driver's license or passport, and proof of your age, such as a birth certificate or a passport.\\\\n\\\\nIt is important to note that some counties in California require a waiting period between the time you obtain the marriage license and the time of the marriage. This waiting period can range from a few days to several weeks, and it is best to check with your county clerk's office for the specific requirements in your county.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ÂâçÂá¶ÁêÜ\n",
        "\n",
        "def process(input_str):\n",
        "    stripped_str = input_str.strip('[]')\n",
        "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
        "    return  ' '.join(sentences)\n",
        "\n",
        "train = train_data.copy()\n",
        "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
        "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
        "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
        "\n",
        "\n",
        "# Drop 'Null' for training\n",
        "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
        "train.drop(indexes, inplace=True)\n",
        "train.reset_index(inplace=True, drop=True)\n",
        "\n",
        "\n",
        "# „ÉÜ„Ç≠„Çπ„ÉàÊ∫ñÂÇô\n",
        "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
        "print(train['text'][0])\n",
        "\n",
        "#Ê≠£Ëß£„É©„Éô„É´‰ΩúÊàê\n",
        "def label_to_int(row):\n",
        "    if row['winner_model_a'] == 1:\n",
        "        return 0\n",
        "    elif row['winner_model_b'] == 1:\n",
        "        return 1\n",
        "    elif row['winner_tie'] == 1:\n",
        "        return 2\n",
        "    else:\n",
        "        print('Error')\n",
        "        return None\n",
        "\n",
        "train['labels'] = train[['winner_model_a', 'winner_model_b', 'winner_tie']].apply(lambda x: label_to_int(x),axis=1)\n",
        "\n",
        "\n",
        "display(train.head(5))\n",
        "\n",
        "# if Train_half:\n",
        "#     train = train[-int(len(train) * 0.5):].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa6kvATjjwZW",
        "outputId": "25466657-7dc2-4103-d33c-4eecd37879f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 142/142 [00:00<00:00, 491.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.8 s, sys: 1.19 s, total: 34 s\n",
            "Wall time: 8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.add_eos_token = True\n",
        "\n",
        "data = train.copy()\n",
        "\n",
        "# Utility function giving token length\n",
        "def get_token_lengths(texts):\n",
        "    # tokenize and receive input_ids for reach text\n",
        "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
        "    # return length of inputs_ids for each text\n",
        "    return [len(t) for t in input_ids]\n",
        "\n",
        "def get_inputs(texts):\n",
        "    # tokenize and receive input_ids for reach text\n",
        "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
        "    # return length of inputs_ids for each text\n",
        "    return input_ids\n",
        "\n",
        "prompt_inputs = get_inputs(data['prompt'])\n",
        "res_a_inputs = get_inputs(data['response_a'])\n",
        "res_b_inputs = get_inputs(data['response_b'])\n",
        "data['total_tokens'] = get_token_lengths(data['text'])\n",
        "\n",
        "\n",
        "#max_length„ÇíË∂Ö„Åà„ÇãÊñáÁ´†„Éá„Éº„Çø„ÅÆ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÇíÂèñÂæó\n",
        "indicies = data[data['total_tokens']>MAX_LENGTH].index\n",
        "\n",
        "#„Éà„Éº„ÇØ„É≥„ÇíË™øÊï¥„Åó„Å¶„ÄÅ„Éá„Ç≥„Éº„ÉâÂá¶ÁêÜ„ÄÅ„Éá„Éº„Çø„Éï„É¨„Éº„É†„Å´Ë™øÊï¥„Åó„ÅüÊñáÁ´†„ÇíÊàª„ÅôÂá¶ÁêÜ\n",
        "\n",
        "from tqdm import tqdm\n",
        "def assign_tokens(data, indicies, max_length):\n",
        "\n",
        "    for ind in tqdm(indicies):\n",
        "\n",
        "        # „Éà„Éº„ÇØ„É≥Èï∑ÂèñÂæó\n",
        "        len_p = len(prompt_inputs[ind])\n",
        "        len_a = len(res_a_inputs[ind])\n",
        "        len_b = len(res_b_inputs[ind])\n",
        "        total = len_p + len_a + len_b\n",
        "\n",
        "        # Ââ≤„ÇäÂΩì„Å¶„Çã„Éà„Éº„ÇØ„É≥Êï∞„Çí„Åù„Çå„Åû„ÇåË®≠ÂÆö\n",
        "        p_assign = int((len_p / total) * max_length)\n",
        "        a_assign = int((len_a / total) * max_length)\n",
        "        b_assign = max_length - (p_assign + a_assign)\n",
        "\n",
        "        # „Éà„Éº„ÇØ„É≥„ÇíÂÖàÈ†≠„Åã„Çâ„Çπ„É©„Ç§„Çπ\n",
        "        prompt_inputs[ind] = prompt_inputs[ind][:p_assign]\n",
        "        res_a_inputs[ind] = res_a_inputs[ind][:a_assign]\n",
        "        res_b_inputs[ind] = res_b_inputs[ind][:b_assign]\n",
        "\n",
        "        # „Éá„Ç≥„Éº„Éâ„Åó„Å¶„Éá„Éº„Çø„Å´Ê†ºÁ¥ç\n",
        "        data.loc[ind, 'prompt'] = tokenizer.decode(prompt_inputs[ind], skip_special_tokens=True)\n",
        "        data.loc[ind, 'response_a'] = tokenizer.decode(res_a_inputs[ind], skip_special_tokens=True)\n",
        "        data.loc[ind, 'response_b'] = tokenizer.decode(res_b_inputs[ind], skip_special_tokens=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "train = assign_tokens(data, indicies, MAX_LENGTH)\n",
        "\n",
        "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
        "\n",
        "dataset = Dataset.from_pandas(train[['text', 'labels']])\n",
        "\n",
        "del data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "19927ce97e39472eaf246fdb88617405",
            "6fb4255021014dfabdd523fed2a4aaaa",
            "070a3b70fe874a3aa61e2c84df1547b0",
            "e5ed6ec6e04648fca0bdbf582fa6ece3",
            "bcd973d50ff447e2a69cb6878cc4829a",
            "7d44f22b37b54748b5bbeffdc7c80294",
            "6494862c170b4c73b0997c2633ad76cb",
            "5ccadd801e494a6892decb2f1e10d927",
            "63ddcb24cd444b6eb96385a32846c231",
            "53fd4d5cefe54885937530a16687c200",
            "d9f155cd087d4fa5bd5fad0bc2c76785"
          ]
        },
        "id": "8QhyTIdYMG69",
        "outputId": "0c653a09-fba3-4654-d844-c3a95d6efff4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7539 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19927ce97e39472eaf246fdb88617405"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19.6 s, sys: 314 ms, total: 20 s\n",
            "Wall time: 6.21 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2-tokenizer/tokenizer_config.json',\n",
              " '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2-tokenizer/special_tokens_map.json',\n",
              " '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2-tokenizer/tokenizer.model',\n",
              " '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2-tokenizer/added_tokens.json',\n",
              " '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2-tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "%%time\n",
        "data = pd.DataFrame()\n",
        "\n",
        "#add_prefix_spaceÔºùÂêÑÂçòË™û„ÅÆÂâç„Å´„Çπ„Éö„Éº„Çπ„ÇíËøΩÂä†„Åô„Çã„Åã„Å©„ÅÜ„Åã\n",
        "#True„Å†„Å®Â§öË®ÄË™û„Å´ÂØæ„Åô„ÇãÂçòË™ûÂàÜÂâ≤„ÅÆÊÄßËÉΩ„ÅåÂêë‰∏ä„Åô„Çã„Åå„ÄÅ„É°„É¢„É™‰ΩøÁî®ÈáèÂ¢óÂä†„Åô„Çã\n",
        "#True„Åô„Çã„Å®„Éà„Éº„ÇØ„É≥Êï∞„Å´Ëã•Âπ≤ÂΩ±Èüø„Åß„ÇãÔºàÂÖÉ„ÅÆÊñá„ÅÆÂÖàÈ†≠„Å´„Çπ„Éö„Éº„Çπ„Åå„Å™„ÅÑ„ÇÇ„ÅÆ„ÇÑÊó•Êú¨Ë™û„ÇÑ‰∏≠ÂõΩË™û„ÅØÁâπ„Å´„Éà„Éº„ÇØ„É≥Êï∞Â¢ó„Åà„ÇãÔºâÔºùÔºûÊÇ™ÂΩ±Èüø„Å†„Å£„Åü„Åã„ÇÇ„Åó„Çå„Å™„ÅÑ„Åß„Åô\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,\n",
        "#                                         #   add_prefix_space=True\n",
        "#                                           )\n",
        "\n",
        "#„Éë„Éá„Ç£„É≥„Ç∞„Å®EOS(end of sequence(ÊñáÁ´†„ÅÆÁµÇÁ´Ø))„ÅÆ„Éà„Éº„ÇØ„É≥„ÇíÂêå„Åò„ÇÇ„ÅÆ„Å´„Åù„Çç„Åà„ÇãÂá¶ÁêÜ\n",
        "#„Åì„Çå„Å´„Çà„Çä„ÄÅË™ûÂΩô„Çµ„Ç§„Ç∫„ÅÆÊ∏õÂ∞ë„Å´„Çà„Çã„É°„É¢„É™ÂäπÁéá„ÅÆÂêë‰∏ä„Å®„É¢„Éá„É´ÊÄßËÉΩ„ÅÆÂêë‰∏ä„ÅÆÂèØËÉΩÊÄß„ÇíÁ¢∫‰øù„Åó„Å¶„ÅÑ„Çã\n",
        "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def data_preprocesing(row):\n",
        "    return tokenizer(row['text'], truncation=True, padding='max_length',\n",
        "                       max_length=MAX_LENGTH)\n",
        "\n",
        "tokenized_data = dataset.map(data_preprocesing, batched=True, remove_columns=['text'])\n",
        "tokenized_data.set_format(\"torch\")\n",
        "\n",
        "#„Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº„ÅÆ‰øùÂ≠ò\n",
        "tokenizer.save_pretrained('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2-tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gWfFIKYaOQv",
        "outputId": "393ec0e5-b27c-4c50-b1aa-f7b7d8f21e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7539, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenized_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAbUHpolMs1j"
      },
      "outputs": [],
      "source": [
        "# BitsAndBytes configuration\n",
        "# 8bitÈáèÂ≠êÂåñ„ÇíÈÅ©Áî®\n",
        "bnb_config =  BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    # load_in_4bit = True,\n",
        "    # bnb_8bit_compute_dtype=torch.float16,\n",
        "    # bnb_8bit_use_double_quant=False\n",
        "    )\n",
        "\n",
        "# Load base model on GPU 0\n",
        "device0 = torch.device('cuda:0')\n",
        "\n",
        "if RESUME_TRAIN == False:\n",
        "    base_model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=3,\n",
        "        torch_dtype=torch.float32,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map='cuda:0',\n",
        "        # output_hidden_states=True         # ÁâπÂæ¥Ê¨°ÂÖÉ„ÅÆÂá∫Âäõ„ÇíÊÆã„Åô„Åã„Å©„ÅÜ„Åã\n",
        "        )\n",
        "\n",
        "    base_model_0.config.pad_token_id = tokenizer.pad_token_id    #„É¢„Éá„É´„ÅÆ„Éë„Éá„Ç£„É≥„Ç∞id„Çí„Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº„Å®„Åù„Çç„Åà„Çã\n",
        "    base_model_0.config.use_cache = False                        #ÈÅéÂéª„ÅÆË®àÁÆóÁµêÊûú„Çí‰øùÊåÅ„Åô„Çã„Åã„Å©„ÅÜ„ÅãÔºà„É°„É¢„É™ÂäπÁéá„ÅÆ„Åü„ÇÅFalse„Å´Ë®≠ÂÆöÔºâ\n",
        "    base_model_0.config.pretraining_tp = 1                       #‰ΩøÁî®GPU„Çí‰∏Ä„Å§„Å´ÈôêÂÆö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7ODNTuzNvCj"
      },
      "outputs": [],
      "source": [
        "# LoRa configuration\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=32,                                     #LoRA„ÅÆ„É©„É≥„ÇØÔºàÂ∞è„Åï„ÅÑ„Åª„Å©„É°„É¢„É™Ê∂àË≤ªÊäë„Åà„ÇãÔºâ\n",
        "    lora_alpha=64,                            #LoRA„Ç¢„ÉÄ„Éó„Çø„Éº„ÅÆÂ≠¶ÁøíÁéá\n",
        "    lora_dropout=0.05,\n",
        "    bias='none',\n",
        "    task_type=TaskType.SEQ_CLS,               #„É¢„Éá„É´„ÅÆ„Çø„Çπ„ÇØ„Çø„Ç§„ÉóÔºàÂ∫èÂàóÂàÜÈ°û„Çø„Çπ„ÇØÔºâ„ÇíÊåáÂÆö\n",
        "    target_modules=['o_proj', \"v_proj\",\n",
        "                    \"q_proj\", \"k_proj\",\n",
        "                    'down_proj', 'gate_proj', 'up_proj'\n",
        "                     ]                              # „É¢„Éá„É´ÂÜÖ„ÅÆ„Å©„ÅÆÂ±§„ÇíÊõ¥Êñ∞„Åô„Çã„Åã„ÇíÂà∂Âæ°„ÄÇ\n",
        "        )\n",
        "\n",
        "# Get peft\n",
        "if RESUME_TRAIN == False:\n",
        "    model_0 = prepare_model_for_kbit_training(base_model_0)\n",
        "    model_0 = get_peft_model(model_0, peft_config).to(device0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0hkYRrP9wBZ"
      },
      "outputs": [],
      "source": [
        "#ÊòéÁ§∫ÁöÑ„Å´„É°„É¢„É™Ëß£Êîæ„ÇíË°å„ÅÜ\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afu4_ItkQz-v"
      },
      "outputs": [],
      "source": [
        "#„Éê„ÉÉ„ÉÅÂá¶ÁêÜ„ÅÆ„Åü„ÇÅ„ÅÆÈñ¢Êï∞ÔºàÈÅ©Áî®„Åô„Çã„Å®„ÄÅ„Éê„ÉÉ„ÉÅ„Åî„Å®„Å´„Éá„Éº„ÇøÈï∑„Çí„Åù„Çç„Åà„ÇãÔºâ\n",
        "#„Å™„Åè„Å¶„ÇÇÂãï‰Ωú„ÅØ„Åó„Åù„ÅÜ„Åß„Åô„Åå„ÄÅ„Åä„Åæ„Åò„Å™„ÅÑÁöÑ„Å´ÂÖ•„Çå„Åæ„Åó„Åü\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz-gFpd18QkD"
      },
      "outputs": [],
      "source": [
        "# #Ë®ìÁ∑¥ÂèØËÉΩ„Å™„Éë„É©„É°„Éº„Çø„Éº„ÅÆÊÉÖÂ†±ÂèñÂæóÔºàlora„Å™„Å©„ÅÆË®≠ÂÆöÂæå„Å´„Å°„ÇÉ„Çì„Å®Ë®≠ÂÆöÊÉÖÂ†±„Åå„É¢„Éá„É´„Å´Ë∏èË•≤„Åï„Çå„Å¶„ÅÑ„Çã„Åã„ÇíÁ¢∫Ë™çÔºâ\n",
        "# MODEL_LAYERS_ROWS = []\n",
        "# TRAINABLE_PARAMS = []\n",
        "# N_TRAINABLE_PARAMS = 0\n",
        "\n",
        "# for name, param in base_model_0.named_parameters():\n",
        "#     # Layer Parameter Count\n",
        "#     n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
        "#     # Only Trainable Layers\n",
        "#     if param.requires_grad:\n",
        "#         # Add Layer Information\n",
        "#         MODEL_LAYERS_ROWS.append({\n",
        "#             'param': n_parameters,\n",
        "#             'name': name,\n",
        "#             'dtype': param.data.dtype,\n",
        "#         })\n",
        "#         # Append Trainable Parameter\n",
        "#         TRAINABLE_PARAMS.append({ 'params': param })\n",
        "#         # Add Number Of Trainable Parameters\"\n",
        "#         N_TRAINABLE_PARAMS += n_parameters\n",
        "\n",
        "# display(pd.DataFrame(MODEL_LAYERS_ROWS))\n",
        "\n",
        "# print(f\"\"\"\n",
        "# ===============================\n",
        "# N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}\n",
        "# N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}\n",
        "# ===============================\n",
        "# \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApO4uxlZIJIn"
      },
      "outputs": [],
      "source": [
        "#Ë©ï‰æ°Èñ¢Êï∞„ÅÆÂÆöÁæ©ÔºàÊ§úË®º„Éá„Éº„Çø„ÇíË®ìÁ∑¥ÊôÇ„Å´Ê∏°„Åô„ÅÆ„Åß„ÅÇ„Çå„Å∞„ÄÅÂøÖË¶ÅÔºâ\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import EvalPrediction\n",
        "\n",
        "# def compute_metrics(evaluations):\n",
        "#     predictions, labels = evaluations\n",
        "#     if isinstance(predictions, list):\n",
        "#         for i, pred in enumerate(predictions):\n",
        "#             print(f\"Prediction {i} shape: {np.array(pred).shape}\")\n",
        "\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),\n",
        "#     'accuracy':accuracy_score(predictions,labels)}\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    predictions, labels = p.predictions, p.label_ids\n",
        "\n",
        "    # predictions„Åå„Çø„Éó„É´„Åß„ÅÇ„ÇãÂ†¥Âêà„ÄÅ„Åù„ÅÆÂÜÖÂÆπ„ÇíÁ¢∫Ë™ç\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "\n",
        "    # predictions„Åålogits„ÅÆÂ†¥Âêà„ÄÅargmax„ÇíÂèñ„Å£„Å¶„ÇØ„É©„Çπ„É©„Éô„É´„Å´Â§âÊèõ\n",
        "    if predictions.ndim == 2:\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Á≤æÂ∫¶„ÇíË®àÁÆó\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmIn1fYpMUl9"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if class_weights is not None:\n",
        "            self.class_weights = torch.tensor(class_weights,\n",
        "            dtype=torch.float32).to(self.args.device)\n",
        "        else:\n",
        "            self.class_weights = None\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\").long()\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
        "        else:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCmbiHvjYvBs"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "        output_dir = '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/lmsys_classification',\n",
        "        learning_rate = 5e-5,\n",
        "        per_device_train_batch_size = BATCH_SIZE,\n",
        "        gradient_accumulation_steps = 2,\n",
        "        per_device_eval_batch_size = BATCH_SIZE,\n",
        "        num_train_epochs = 1,\n",
        "        logging_steps=10,                 # ÈÄî‰∏≠ÁµåÈÅé„ÅÆÂá∫ÂäõÈ†ªÂ∫¶\n",
        "        weight_decay = 0.01,\n",
        "        save_strategy=\"steps\",             # „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Çí„Çπ„ÉÜ„ÉÉ„Éó„Åî„Å®„Å´‰øùÂ≠ò\n",
        "        # evaluation_strategy=\"steps\",     # Ê§úË®º„Çísteps„Åî„Å®„Å´Ë©ï‰æ°\n",
        "        # load_best_model_at_end = True,   # Ê§úË®º„Éá„Éº„Çø„Å´ÂØæ„Åô„ÇãÊúÄ„ÇÇÂÑ™ÁßÄ„Å™„É¢„Éá„É´„ÅÆÈáç„Åø„Çí‰øùÂ≠ò\n",
        "        report_to=\"none\",                  # wandb„Å´‰øùÂ≠ò„Åó„Å™„ÅÑ„Çà„ÅÜ„Å´Ë™øÊï¥\n",
        "        save_steps=100,                    # ‰øùÂ≠ò„Åô„Çã„Çπ„ÉÜ„ÉÉ„ÉóÊï∞„ÇíË™øÊï¥\n",
        "        fp16=True,                         # AMP„ÇíÊúâÂäπ„Å´„Åô„Çã\n",
        "        # gradient_checkpointing=True  # Gradient Checkpointing„ÇíÊúâÂäπ„Å´„Åô„Çã\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bOnkafJkrPL"
      },
      "outputs": [],
      "source": [
        "# if not RESUME_TRAIN:\n",
        "#     train_test_dataset = tokenized_data.train_test_split(test_size=0.1)\n",
        "#     train_test_dataset['test']\n",
        "#     train_test_dataset['test'].to_csv('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/Ê§úË®ºÁî®„Éá„Éº„Çø.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wat63lOuEPrW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGoVodj1PBJ7",
        "outputId": "ec269b15-485a-429f-f1fd-1309c1a55238"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 7539\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tokenized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GGGIW0nJMnES"
      },
      "outputs": [],
      "source": [
        "if not RESUME_TRAIN:\n",
        "    trainer = CustomTrainer(\n",
        "        model = model_0,\n",
        "        args = training_args,\n",
        "        train_dataset = tokenized_data,\n",
        "        # eval_dataset = train_test_dataset['test'],\n",
        "        data_collator = collate_fn,\n",
        "        compute_metrics = compute_metrics,\n",
        "        class_weights=class_weights,\n",
        "    )\n",
        "\n",
        "    train_result = trainer.train()\n",
        "    trainer.save_model('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/Gemma2_fine-tuning')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE-tSvxSlx3s"
      },
      "source": [
        "„ÉÜ„É≥„ÇΩ„É´Âûã„Åß„É¢„Éá„É´„ÅÆÈáç„Åø„Éë„É©„É°„Éº„Çø„Éº„ÅÆ‰øùÂ≠ò  \n",
        "kaggle„Åß„É¢„Éá„É´„ÅÆÈáç„Åø„Çí‰∫ãÂâçÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„Åã„ÇâÊõ¥Êñ∞„Åô„Çã„Å®„Åç„Å´ÂøÖË¶Å"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JUGSLnrjYyY"
      },
      "outputs": [],
      "source": [
        "#torch„Åß‰øùÂ≠òÔºàkaggle„Å®„ÅÆ‰∫íÊèõÊÄß„ÇíÁ¢∫‰øùÔºâ\n",
        "\n",
        "# device0 = torch.device('cuda:0')\n",
        "\n",
        "# check_point_dir = '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/lmsys_classification/checkpoint-1797'\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2-tokenizer')\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "# tokenizer.padding_side = 'right'\n",
        "# tokenizer.add_eos_token = True\n",
        "\n",
        "# # 8bitÈáèÂ≠êÂåñ„ÇíÈÅ©Áî®\n",
        "# bnb_config =  BitsAndBytesConfig(\n",
        "#     load_in_8bit=True,\n",
        "#     # load_in_4bit = True,\n",
        "#     # bnb_8bit_compute_dtype=torch.float16,\n",
        "#     # bnb_8bit_use_double_quant=False\n",
        "#     )\n",
        "\n",
        "# base_model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "#         check_point_dir,\n",
        "#         num_labels=3,\n",
        "#         torch_dtype=torch.float32,\n",
        "#         quantization_config=bnb_config,\n",
        "#         device_map='cuda:0',\n",
        "#         # output_hidden_states=True         # ÁâπÂæ¥Ê¨°ÂÖÉ„ÅÆÂá∫Âäõ„ÇíÊÆã„Åô„Åã„Å©„ÅÜ„Åã\n",
        "#         )\n",
        "\n",
        "# base_model_0.config.pad_token_id = tokenizer.pad_token_id    #„É¢„Éá„É´„ÅÆ„Éë„Éá„Ç£„É≥„Ç∞id„Çí„Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº„Å®„Åù„Çç„Åà„Çã\n",
        "# base_model_0.config.use_cache = False                        #ÈÅéÂéª„ÅÆË®àÁÆóÁµêÊûú„Çí‰øùÊåÅ„Åô„Çã„Åã„Å©„ÅÜ„ÅãÔºà„É°„É¢„É™ÂäπÁéá„ÅÆ„Åü„ÇÅFalse„Å´Ë®≠ÂÆöÔºâ\n",
        "# base_model_0.config.pretraining_tp = 1                       #‰ΩøÁî®GPU„Çí‰∏Ä„Å§„Å´ÈôêÂÆö\n",
        "\n",
        "\n",
        "# peft_config = LoraConfig(\n",
        "#     r=4,                                     #LoRA„ÅÆ„É©„É≥„ÇØÔºàÂ∞è„Åï„ÅÑ„Åª„Å©„É°„É¢„É™Ê∂àË≤ªÊäë„Åà„ÇãÔºâ\n",
        "#     lora_alpha=8,                            #LoRA„Ç¢„ÉÄ„Éó„Çø„Éº„ÅÆÂ≠¶ÁøíÁéá\n",
        "#     lora_dropout=0.05,\n",
        "#     bias='none',\n",
        "#     task_type=TaskType.SEQ_CLS,               #„É¢„Éá„É´„ÅÆ„Çø„Çπ„ÇØ„Çø„Ç§„ÉóÔºàÂ∫èÂàóÂàÜÈ°û„Çø„Çπ„ÇØÔºâ„ÇíÊåáÂÆö\n",
        "#     target_modules=['o_proj', \"v_proj\",\n",
        "#                     #  \"q_proj\", \"k_proj\"\n",
        "#                      ]                              # „É¢„Éá„É´ÂÜÖ„ÅÆ„Å©„ÅÆÂ±§„ÇíÊõ¥Êñ∞„Åô„Çã„Åã„ÇíÂà∂Âæ°„ÄÇ\n",
        "#         )\n",
        "\n",
        "# # Get peft\n",
        "# model_0 = prepare_model_for_kbit_training(base_model_0)\n",
        "# model_0 = get_peft_model(model_0, peft_config).to(device0)\n",
        "\n",
        "# model = model_0.cpu()\n",
        "# torch.save(dict([(k,v) for k, v in model.named_parameters() if v.requires_grad]), '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2_finetuned_model.pth')\n",
        "\n",
        "# model = base_model_0.cpu()\n",
        "# torch.save(model.state_dict(), '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/gemma2_finetuned_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIba4OMt1E0H"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "# from sklearn.metrics import balanced_accuracy_score, classification_report\n",
        "\n",
        "# def get_performance_metrics(test_df):\n",
        "#     y_test = test_df.label\n",
        "#     y_pred = test_df.predictions\n",
        "\n",
        "#     print(\"Classification Report:\")\n",
        "#     print(classification_report(y_test, y_pred))\n",
        "\n",
        "#     print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
        "#     print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# def generate_predictions(model,df_test):\n",
        "#     sentences = df_test.text.tolist()\n",
        "#     batch_size = 8\n",
        "#     all_outputs = []\n",
        "\n",
        "#     for i in range(0, len(sentences), batch_size):\n",
        "\n",
        "#         batch_sentences = sentences[i:i + batch_size]\n",
        "\n",
        "#         inputs = tokenizer(batch_sentences, return_tensors=\"pt\",\n",
        "#         padding=True, truncation=True, max_length=1536)\n",
        "\n",
        "#         inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#         for k, v in inputs.items()}\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             outputs = model(**inputs)\n",
        "#             all_outputs.append(outputs['logits'])\n",
        "\n",
        "#     final_outputs = torch.cat(all_outputs, dim=0)\n",
        "#     df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
        "\n",
        "# test_df = train.sample(100).reset_index(drop=True)\n",
        "# generate_predictions(model_0,test_df)\n",
        "# get_performance_metrics(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm1UX84Vb7A8"
      },
      "source": [
        "# Resume Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "de1a80ac229742899df4783f93a62b77",
            "e895ebc679c74296a60e4970fb1e143f",
            "5dae86f7be9c470fa256522989f84ef1",
            "cfe637e00d7d4356a15c7627a386a5a2",
            "c87e7346eef1412f8b287bb522afabd5",
            "ac2b9dfcad8b454aa22e3c388dab91b4",
            "37a51e4db3b542699886e5b33b7ba950",
            "d5525f7899cd457bbdce7be7db00ba05",
            "c77103a2c1e84db0a8e2d64d4fd107b4",
            "9619db65a35640159b8687b3de6aa142",
            "9616d021e12349fe828b84003a299383"
          ]
        },
        "id": "L-uZ6koeJs75",
        "outputId": "5263443b-e7d9-4b98-b71b-4e6a35d320c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de1a80ac229742899df4783f93a62b77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if RESUME_TRAIN:\n",
        "    checkpoint_dir = '/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/lmsys_classification/checkpoint-7185'\n",
        "\n",
        "    saved_model = Gemma2ForSequenceClassification.from_pretrained(\n",
        "        checkpoint_dir,\n",
        "        num_labels=3,\n",
        "        torch_dtype=torch.float32,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map='cuda:0',)\n",
        "\n",
        "\n",
        "    saved_model.config.pad_token_id = tokenizer.pad_token_id    #„É¢„Éá„É´„ÅÆ„Éë„Éá„Ç£„É≥„Ç∞id„Çí„Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº„Å®„Åù„Çç„Åà„Çã\n",
        "    saved_model.config.use_cache = False                        #ÈÅéÂéª„ÅÆË®àÁÆóÁµêÊûú„Çí‰øùÊåÅ„Åô„Çã„Åã„Å©„ÅÜ„ÅãÔºà„É°„É¢„É™ÂäπÁéá„ÅÆ„Åü„ÇÅFalse„Å´Ë®≠ÂÆöÔºâ\n",
        "    saved_model.config.pretraining_tp = 1                       #‰ΩøÁî®GPU„Çí‰∏Ä„Å§„Å´ÈôêÂÆö\n",
        "\n",
        "    # Get peft\n",
        "    saved_model = prepare_model_for_kbit_training(saved_model)\n",
        "    saved_model = get_peft_model(saved_model, peft_config).to(device0)\n",
        "    saved_model.train()\n",
        "\n",
        "\n",
        "    # saved_model = PeftModel.from_pretrained(saved_model, checkpoint_dir)\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        model = saved_model,\n",
        "        args = training_args,\n",
        "        train_dataset = tokenized_data,\n",
        "        # eval_dataset = train_test_dataset['test'],\n",
        "        data_collator = collate_fn,\n",
        "        compute_metrics = compute_metrics,\n",
        "        class_weights=class_weights,\n",
        "    )\n",
        "\n",
        "\n",
        "    train_result = trainer.train(resume_from_checkpoint=True, ignore_data_skip=True)\n",
        "    trainer.save_model('/content/drive/Shared drives/BLM_AIÈñãÁô∫ÂÆ§ÂÖ±Êúâ/05_Kaggle/ÂÖ±Êúâ/lmsys_classification/finetuned-Gemma2-0718')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DrTAnR0hjQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf8baea78d8241e2b9f62ce5d8e7eaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4443be4102a243ed9810a7379ff9c83c",
              "IPY_MODEL_3ecfd288fd564012ae4b92cb54d8dc86",
              "IPY_MODEL_e305fbe7054d4ad9962d2a0059b719ce",
              "IPY_MODEL_8e66430b20e44ce486a67178f2934490",
              "IPY_MODEL_554fe1c145af498385e71451a7dfe038"
            ],
            "layout": "IPY_MODEL_c18cc59d0638437da4e54144ba0146ee"
          }
        },
        "4443be4102a243ed9810a7379ff9c83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6195521652a74aa7b944d5f85fdd23be",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bc5b97a10676480893b7ec43829b97fc",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3ecfd288fd564012ae4b92cb54d8dc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_562af223e721456987923c265742b3e4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8d2168547b3f48c1bee2d85e2e3551b2",
            "value": ""
          }
        },
        "e305fbe7054d4ad9962d2a0059b719ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_812aedac4bfb48d0985c78e5ecdefc5c",
            "style": "IPY_MODEL_c64dce783fd24a5885083a1b5a6bca73",
            "value": true
          }
        },
        "8e66430b20e44ce486a67178f2934490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8aa1c4e0ff944ba2beaa85ba163a8600",
            "style": "IPY_MODEL_4d9efaef54d14ca7855a432d3da3baae",
            "tooltip": ""
          }
        },
        "554fe1c145af498385e71451a7dfe038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ee53782d804a579a7a8bc7b515a3c4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9aea669922c94334b8409b0ce1d43b34",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "c18cc59d0638437da4e54144ba0146ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6195521652a74aa7b944d5f85fdd23be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5b97a10676480893b7ec43829b97fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "562af223e721456987923c265742b3e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2168547b3f48c1bee2d85e2e3551b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "812aedac4bfb48d0985c78e5ecdefc5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c64dce783fd24a5885083a1b5a6bca73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aa1c4e0ff944ba2beaa85ba163a8600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d9efaef54d14ca7855a432d3da3baae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "21ee53782d804a579a7a8bc7b515a3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aea669922c94334b8409b0ce1d43b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19927ce97e39472eaf246fdb88617405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fb4255021014dfabdd523fed2a4aaaa",
              "IPY_MODEL_070a3b70fe874a3aa61e2c84df1547b0",
              "IPY_MODEL_e5ed6ec6e04648fca0bdbf582fa6ece3"
            ],
            "layout": "IPY_MODEL_bcd973d50ff447e2a69cb6878cc4829a"
          }
        },
        "6fb4255021014dfabdd523fed2a4aaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d44f22b37b54748b5bbeffdc7c80294",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6494862c170b4c73b0997c2633ad76cb",
            "value": "Map:‚Äá100%"
          }
        },
        "070a3b70fe874a3aa61e2c84df1547b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccadd801e494a6892decb2f1e10d927",
            "max": 7539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63ddcb24cd444b6eb96385a32846c231",
            "value": 7539
          }
        },
        "e5ed6ec6e04648fca0bdbf582fa6ece3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53fd4d5cefe54885937530a16687c200",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d9f155cd087d4fa5bd5fad0bc2c76785",
            "value": "‚Äá7539/7539‚Äá[00:05&lt;00:00,‚Äá1408.19‚Äáexamples/s]"
          }
        },
        "bcd973d50ff447e2a69cb6878cc4829a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d44f22b37b54748b5bbeffdc7c80294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6494862c170b4c73b0997c2633ad76cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ccadd801e494a6892decb2f1e10d927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ddcb24cd444b6eb96385a32846c231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53fd4d5cefe54885937530a16687c200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f155cd087d4fa5bd5fad0bc2c76785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1a80ac229742899df4783f93a62b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e895ebc679c74296a60e4970fb1e143f",
              "IPY_MODEL_5dae86f7be9c470fa256522989f84ef1",
              "IPY_MODEL_cfe637e00d7d4356a15c7627a386a5a2"
            ],
            "layout": "IPY_MODEL_c87e7346eef1412f8b287bb522afabd5"
          }
        },
        "e895ebc679c74296a60e4970fb1e143f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac2b9dfcad8b454aa22e3c388dab91b4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_37a51e4db3b542699886e5b33b7ba950",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá‚Äá50%"
          }
        },
        "5dae86f7be9c470fa256522989f84ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5525f7899cd457bbdce7be7db00ba05",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c77103a2c1e84db0a8e2d64d4fd107b4",
            "value": 2
          }
        },
        "cfe637e00d7d4356a15c7627a386a5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9619db65a35640159b8687b3de6aa142",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9616d021e12349fe828b84003a299383",
            "value": "‚Äá2/4‚Äá[00:08&lt;00:08,‚Äá‚Äá4.32s/it]"
          }
        },
        "c87e7346eef1412f8b287bb522afabd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2b9dfcad8b454aa22e3c388dab91b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a51e4db3b542699886e5b33b7ba950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5525f7899cd457bbdce7be7db00ba05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77103a2c1e84db0a8e2d64d4fd107b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9619db65a35640159b8687b3de6aa142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9616d021e12349fe828b84003a299383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}